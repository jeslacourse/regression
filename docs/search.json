[{"path":"index.html","id":"regression-analysis","chapter":"Regression Analysis","heading":"Regression Analysis","text":"SummaryThis text serves personal notebook regression notes. ’s also space explore different formats styles sharing information. version written Rstudio using bookdown bootstrap.Linear Regression measure linear relationship two variables.Regression used observational studies experimental studies. Observational studies experiments manipulation researcher treatments randomized. Experimental studies allow researcher manipulate explanatory variables treatment data must randomized.","code":""},{"path":"single-linear-regression.html","id":"single-linear-regression","chapter":"1 Single Linear Regression","heading":"1 Single Linear Regression","text":"One predictor, one outcomeIn SummaryThis section serves introduction expectation, variance, bias, modeling. topics serve building blocks linear regression. sample re-sample data repeated, ’ll start see statistics, estimates, start mirror true parameters emulate.","code":""},{"path":"single-linear-regression.html","id":"variables","chapter":"1 Single Linear Regression","heading":"1.1 Variables","text":"Single variable regression one continuous response variable (\\(y\\)) one explanatory variable (\\(x\\)). response variable, \\(y\\) also known dependent outcome variable. Explanatory variables, \\(x\\) aka independent, predictor, covariate variables, can include continuous categorical values. also two parameters regression: \\(\\beta_0\\) y-intercept \\(\\beta_1\\) slope function. four components make linear regression equation, variant slope-intercept form.\\[y=\\beta_0 + \\beta_1x\\]","code":""},{"path":"single-linear-regression.html","id":"fixed-and-random-variables","chapter":"1 Single Linear Regression","heading":"Fixed and Random Variables","text":"Fixed variables don’t change one experiment next. values chosen researcher. \\(X\\) treated fixed variable regression. said, regression often used \\(X\\) wholly chosen; may simply data work . example, sampling population return distribution ages may match true distribution population. treat \\(X\\) fixed value, also technically random.Random variables expected return different values repeating experiment. variability true regression line points \\((X,Y)\\) captured error value, \\(\\epsilon\\).\\[\nY=\\beta_0 + \\beta_1X + \\epsilon\n\\]\n\\(\\beta\\)’s considered fixed values along \\(X\\), whereas \\(\\epsilon\\) random variable.\\(Y\\) also random variable given ’s dependency \\(X\\) effects \\(\\epsilon\\).","code":""},{"path":"single-linear-regression.html","id":"parameters-and-statistics","chapter":"1 Single Linear Regression","heading":"Parameters and Statistics","text":"Statistics used estimate true parameters\\(\\beta_0\\) \\(\\beta_1\\) parameters; usually unknown values related population sample.Parameter: values populationStatistic: values sampleAfter collecting data population, can create sample run statistics can estimate parameters.","code":""},{"path":"single-linear-regression.html","id":"expected-values","chapter":"1 Single Linear Regression","heading":"1.2 Expected Values","text":"Expected values mean average values. look little different depending data looks like.Sample means averages. Given sample data \\(X_1... X_n\\), return statistic:Definition 1.1  (Sample Mean) \\[\\begin{equation}\n\\bar{x}  = \\frac{1}{n} \\sum_{= 1}^nX_i\n\n\\end{equation}\\]several repeated experiments, can come population mean, expected value. \\(Z_1..Z_N\\) values population, use parameter:\\[ E(Z) = \\frac{1}{N}\\sum_{=1}^N Z_i\\]general, discrete random variable \\(Y\\) possible values \\(y_1... y_k\\) can say \\(E(Y)\\) weighted average possible values \\(y_1... y_k\\) respective expected probabilities \\(P(Y = y_1)...P(Y = y_k)\\):Definition 1.2  (Expected Value) \\[\\begin{equation}\nE(Y) = \\sum_{=1}^k y_i P(Y = y_i)\\end{equation}\n\\]Expectation discrete values modification weighted average formula. Given limitations probabilities, simply add caveats sum probabilities equal 100%; \\(\\sum w_i = 1\\) \\(0 \\leq w_1 \\leq 1\\).\\[\\begin{equation}\\sum_{=1}^k w_ia_i\\end{equation}\\]Expectation continuous random variable \\(Y\\) calculated density function:\\[E(Y) = \\int_{-\\infty}^{\\infty} yf(y)dy\\]\n’s thing, yet terrible integrals.Example 1.1  normal distribution Y ~ N(0,1) mean 0 variance 1, represented using density function:\\[E(Y) = \\int_{-\\infty}^{\\infty}y\\frac{1}{\\sqrt{2\\pi}}\n  \\exp\\left( -\\frac{y^2}{2}\\right) dy = 0 \\]Rules ExpectationGiven random variables \\(X\\) \\(Y\\) constants \\(,b,\\) & \\(c\\):\\(E(c) = c\\)\\(E(cX) = cE(X)\\)\\(E(X+Y) = E(X) + E(Y)\\)Example 1.2  Use rules expectation simplify equation.\\[\\begin{equation}\nE(+bX+cY) \\\\\n= + (X) + cE(Y)\n\\end{equation}\\]","code":""},{"path":"single-linear-regression.html","id":"variance","chapter":"1 Single Linear Regression","heading":"1.3 Variance","text":"Sample data \\(x_i...x_n\\) give us unbiased sample variance:Definition 1.3  (Sample Variance) \\[\ns^2 = \\frac{\\sum(x_i - \\bar{x})^2}{n-1}\n\\]Focusing denominator, sample sizes \\(n\\) shift statistic significantly compared larger sample.Population variance can defined :Definition 1.4  (Variance) \\[\nvar(Y) = E[Y-E(Y)]^2\n\\]squaring \\([Y-E(Y)]\\) “removes sign”, reverts measures positive distances mean.\ncan use population variance formula show \\(E(Y)\\) equivalent parameter \\(\\mu\\). Given \\(var(Y)\\):\\[\\begin{equation}\n\\begin{split}\nvar(Y) & = E[Y-E(Y)]^2\\\\& =E[Y-\\mu]^2\\\\\\therefore \\mu &= E(Y)\n\\end{split}\n\\end{equation}\\]Given known substitutions, can say:\\[\\begin{equation}\n\\begin{split}  var(Y) & = E[Y-E(Y)]^2\\\\\n& =\\sum_{=1}^k (y_i-\\mu)^2P(Y-y_i)\n\\end{split}\n\\end{equation}\\]\\(Z_1... Z_n\\) account values population, parameter:\\[var(Z) = \\frac{1}{N}\\sum_{=1}^{N}(Z_i-\\bar{Z})^2\\]\\(\\bar{Z} = E(Z)\\).Rules Variance\\(var() = 0\\)\\(var(aX) = ^2 var(X)\\)\\(var(X+Y) = var(X) + var(Y) + 2cov(X,Y)\\)Example 1.3  Use rules variance simplify equation.\n\\[\\begin{equation}\n\\begin{split}\nvar(+bX-cY) \\\\\n&= var() + var(bX-cY) + 2cov(X,Y)\\\\\n&= 0 + var(bX)+ var(-cY) \\\\\n&=b^2var(X) + c^2var(Y)+2[(-bc)cov(X,Y)]\n\\end{split}\n\\end{equation}\\]","code":""},{"path":"single-linear-regression.html","id":"covariance","chapter":"1 Single Linear Regression","heading":"1.4 Covariance","text":"Sample covariance defined :Definition 1.5  (Sample Covariance) \\[\n\\hat{cov}(X,Y) = \\frac{\\sum(X_i - \\bar{X})(Y_i-\\bar{Y})^2}{n-1}\n\\]Given random variables \\((X,Y)\\) can expand definition covariance :Definition 1.6  (Covariance) \\[cov(X,Y) = E[(X -\\mu_x)(Y-\\mu_y)]\\]Rules Covariance\\(cov(X,Y) = cov(Y,X)\\)\\(X ⫫ Y \\Rightarrow cov(X,Y) = 0\\), random variables independent one another, predict variabilityif \\(cov(X,Y)= 0 \\Rightarrow\\) may may \\(X ⫫ Y\\)\\(cov(,b) = 0\\)\\(cov(, X) = 0\\)\\(cov(aX, Y) = cov(X,Y)\\)\\(cov(aX, ) = ab cov(X,Y)\\)\\(cov(X, Y+Z) = cov(X,Y)+cov(X,Z)\\)\\(cov(X,X) = var(X)\\)","code":""},{"path":"single-linear-regression.html","id":"correlation","chapter":"1 Single Linear Regression","heading":"1.5 Correlation","text":"Correlations equal causation non-random studiesCorrelation defined scale \\(-1 \\leq corr(X,Y) \\leq 1\\) :Definition 1.7  (Correlation) \\[\ncorr(X,Y) = \\frac{cov(X,Y)}{\\sqrt{var(X)var(Y)}}\n\\]","code":""},{"path":"single-linear-regression.html","id":"bias","chapter":"1 Single Linear Regression","heading":"1.6 Bias","text":"estimators \\(b_0\\) \\(b_1\\) unbiased estimators. require \\(\\epsilon_i\\), \\(E(\\epsilon_i) = 0\\).\\(E(b_0) =\\beta_0\\) \\(E(b_1) = \\beta_1\\).Bias term refers much estimate (estimator) true value. Contextually, want know far slope intercept sample values experiment deviates true regression line.random variability, \\(s^2\\) vary experiment. repeating experiment can collect unbiased sample variance, average value experiments.\\[ E(s^2) = E\\frac{\\sum(Y_i-\\bar{Y})^2}{n-1}= var(Y)\\]","code":""},{"path":"single-linear-regression.html","id":"examples","chapter":"1 Single Linear Regression","heading":"Examples","text":"Example 1.4  want estimate systolic blood pressure, \\(y\\), 20 subjects based age, \\(x\\). \\(\\beta\\)’s usually unknown, case know want reasonably close \\(\\beta_0=90\\) \\(\\beta_1=0.9\\)mean age, \\(\\bar{x}\\), \\(38.15\\) mean systolic blood pressure measured, \\(\\bar{y}\\) \\(118.11\\) mmHg.First, solve \\(b_1\\):\\[\\begin{equation}\n\\begin{split}\nb_1 &=\\frac{\\hat{cov}(X,Y)}{\\hat{var}(X,Y)}\\\\\n\\hat{cov}(X,Y)&= \\sum_{=1}^{20} (x_i- \\bar x)(y_i - \\bar y)\\approx 4863.282\\\\\n\\hat{var}(X,Y) &= \\sum_{=1}^{20} (x_i- \\bar x) \\approx 6072.55\\\\\nb_1 &= \\frac{4863.282}{6072.55} \\approx 0.8\n\n\\end{split}\n\\end{equation}\\], \\(b_0\\):\\[\\begin{equation}\n\\begin{split}\n\nb_0 &= \\bar{y}- b_1\\bar{x}\\\\\nb_0 &= 118.11- 0.8(38.15)\\\\\nb_0 &\\approx 91.6\n\n\\end{split}\n\\end{equation}\\]estimated regression line:\\[\ny = 0.8x-91.6\n\\]\nroughly comparable true regression line:\\[\ny = 0.9x-90\n\\]Example 1.5  Given values , predicted systolic blood pressure 50-year-old?\\[E(Y|X = 50)\\]Use estimated regression line determine value \\(x_1 = 50\\):\n\\[\\hat y = 0.8(50) - 91.6\\approx 131.6\\]","code":""},{"path":"modeling-and-errors.html","id":"modeling-and-errors","chapter":"2 Modeling and Errors","heading":"2 Modeling and Errors","text":"SummaryModeling critical component regression statistics general. Parameter estimating can allow researcher interpolate, fill gaps, dataset determine key relationships variables outcomes.lot work goes behind scenes determine “well-fit” model underlying data. core understanding different errors, including attributes impacts, fundamental statistical methodology.single linear regression model :\\[Y_i= \\beta_0 +\\beta_1X_i + \\epsilon_i\\]\nmodel called single simple model using one predictor.","code":""},{"path":"modeling-and-errors.html","id":"features-of-models","chapter":"2 Modeling and Errors","heading":"2.1 Features of Models","text":"\\(Y_i\\) outcome variable. \\(Y_i\\) \\(Y_i\\) random experiment sum constant term, \\(\\beta_0 +\\beta_1X_i\\), plus random variable, \\(\\epsilon_i\\).\\(X_i\\) considered fixed value predictor experiment, \\(\\beta_0\\) \\(\\beta_1\\) parameters, usually unknown. goal estimate \\(\\beta_0\\) \\(\\beta_1\\).can estimate \\(E(Y_i|X_i)\\) \\(\\hat y\\) expectation errors zero.Definition 2.1  (Predicted Value Formula) \\[\\begin{equation}\n\\begin{split}\nE(Y_i|X_i)&= \\beta_0 +\\beta_1X_i\\\\\n\\hat y&= b_0 +b_1x_i\n\\end{split}\n\\end{equation}\n\\]expect errors deviate randomly around regression line.Definition 2.2  (Deviation Formula) \\[\\epsilon_i = Y_i -(\\beta_0 +\\beta_1X_i)\\]Example 2.1  want estimate systolic blood pressure 20 year old. know following variables:\\(x\\): age\\(y\\): systolic blood pressure\\(\\beta_0\\): intercept, \\(90\\)\\(\\beta_1\\): slope, \\(0.9\\)Note \\(\\beta\\)’s usually unknown. can say, expect systolic blood pressure \\(90\\) age \\(0\\) (birth), increasing \\(0.9\\) units every year.\\[\\begin{align}\nE(Y|X = 20) \\\\= 90 + 0.9(20)\\\\=108\n\\end{align}\\]Factoring error margin, given \\(X = 20\\) expect \\(Y = 108 +\\epsilon\\). 20-year-old systolic blood pressure around 108.","code":""},{"path":"modeling-and-errors.html","id":"an-introduction-to-residuals","chapter":"2 Modeling and Errors","heading":"2.2 An Introduction to Residuals","text":"expected value \\(\\epsilon\\) regression line.expect variation measured values model true regression function. quantify errors observed error residual, \\(\\epsilon_i\\). residual captures random errors measurement experiment.Residual observation \\(\\):\\(e_i=\\) observed - predictedDefinition 2.3  (Observed Residual Error) \\[\\begin{equation}\n\\begin{split}\ne_i&= y_i - \\hat y\\\\\n&= y_i - (b_0 - b_1x_i)\n\\end{split}\n\\end{equation}\\]need establish properties \\(\\epsilon_i\\):Property 1:\\(E(\\epsilon_i) = 0\\), \\(\\forall \\)average, error regression line, 0.\\[\\begin{equation}\n\\begin{split}\nE(\\epsilon_i) = 0\\\\\n\\epsilon_i &= Y_i -(\\beta_0 +\\beta_1X_i) \\\\\nE[\\epsilon_i] &= E[Y_i -(\\beta_0 +\\beta_1X_i)] \\\\\n0 &= E[Y_i] - E[\\beta_0 +\\beta_1X_i] \\\\\n0 &= E[Y_i] - E[\\beta_0] +E[\\beta_1X_i] \\\\\n0  &= E[Y_i] - \\beta_0 + \\beta_1X_i \\\\\n   \\Rightarrow E[Y_i] = \\beta_0 + \\beta_1X_i \\\\\n   \n\\end{split}\n\\end{equation}\\]showing average, \\(Y_i\\) falls along regression line. can say regression line average \\(Y_i\\), conditional \\(X_i\\).\\[ E(Y_i|X_i)= \\beta_0 +\\beta_1X_i \\]\nProperty 2:\\(\\epsilon_i...\\epsilon_n\\) constant variance.Define \\(\\sigma^2(\\epsilon_i) \\equiv \\sigma^2\\), $^2(Y_i) = var(Y_i) $.\\(var(\\epsilon_i)\\) increases \\(X\\) increases.Property 3:\\(\\epsilon_i...\\epsilon_n\\) uncorrelated.\\[\\begin{equation}\n\\begin{split}\n  corr(\\epsilon_i,\\epsilon_j) &= 0, \\neq j \\\\\n  corr(\\epsilon_i,\\epsilon_j) &= var(\\epsilon_i) \\neq 0 \\\\\n  cov(\\epsilon_i,\\epsilon_j) &= 0, \\neq j\n\\end{split}\n\\end{equation}\\]Similarly, different notation, \\(corr(\\epsilon_i,\\epsilon_j) = \\sigma(\\epsilon_i,\\epsilon_j)\\).Property 4:\\(\\epsilon_i...\\epsilon_n\\) normally distributed.","code":""},{"path":"modeling-and-errors.html","id":"estimating-betas","chapter":"2 Modeling and Errors","heading":"2.3 Estimating \\(\\beta\\)’s","text":"can find good estimates \\(\\beta_0\\) \\(\\beta_1\\) using least squares method, \\(b_0\\) \\(b_1\\) unbiased least squares estimates.\\(n\\) pairs data, \\((x_1, y_1)...(x_n, y_n)\\):Compose squared deviation formula residual formula (Defn []):\\[e_i^2 = [y_i - (\\beta_0 +\\beta_1x_i)]^2\\]allow us define \\(Q\\), sum squared deviations:Definition 2.4  (Sum Squared Deviation ) \\[\\begin{equation}\n\\begin{split}\nQ &\\equiv \\sum_{= 1}^n e_i^2\\\\&=\\sum_{= 1}^n [y_i - (\\beta_0 +\\beta_1x_i)]^2\n\\end{split}\n\\end{equation}\\]least squares estimates values \\(\\beta_0\\) \\(\\beta_1\\) minimize \\(Q\\).use \\(b_1\\) estimate slope \\(\\beta_1\\):Definition 2.5  (Estimation Regression Slope) \\[\\begin{equation}\n\\begin{split}\n\nb_1 &=\\frac{\\hat{cov}(X,Y)}{\\hat{var}(X,Y)} \\\\\n&= \\frac{\\sum(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum(x_i-\\bar{x})^2}\n\\end{split}\n\\end{equation}\\]sampling distribution \\(b_1\\) normal.\n\\[ b_1\\sim N\\]\\(b_1\\), estimate intercept \\(\\beta_0\\) straightforward:Definition 2.6  (Estimation Regression Intercept) \\[\\begin{equation}\n\\begin{split}\nb_0 = \\bar{y}- b_1\\bar{x}\\\\\n\\end{split}\n\\end{equation}\\]point \\((\\bar{x}, \\bar{y})\\) falls along regression line.","code":""},{"path":"modeling-and-errors.html","id":"linear-combinations","chapter":"2 Modeling and Errors","heading":"2.3.1 Linear Combinations","text":"linear combination set values \\(a_1...a_n\\) formula:\\[\n\\sum_{=1}^n c_ia_i\n\\]\\(c_1...c_n\\) constants.Using notation can estimate \\(b_1\\):\\[\nb_1 = \\frac{\\sum(x_i-\\bar{x}) y_i}{\\sum(x_i-\\bar{x})^2}\n\\]factors exclusive \\(y_i\\) render constant \\(c_i\\).","code":""},{"path":"modeling-and-errors.html","id":"errors","chapter":"2 Modeling and Errors","heading":"2.4 Errors","text":"SSE: Sum Squared ErrorsThe residual sum squares.Definition 2.7  (Sum Squared Errors) \\[\\begin{equation}\n\\begin{split}\nSSE &= \\sum_{= 1}^n e_i^2\\\\\n&= \\sum_{= 1}^n (y_i - \\hat y)^2\n\n\\end{split}\n\\end{equation}\\]MSE: Mean Squared ErrorsDefinition 2.8  (Mean Squared Errors) \\[\\begin{equation}\n\\begin{split}\nMSE &= \\frac{\\sum_{= 1}^n (y_i - \\hat y)^2}{n-2} \\\\\n&= \\frac{SSE}{n-2}\n\n\\end{split}\n\\end{equation}\\]\\(n-2\\) degrees freedom estimating two parameters, \\(\\beta_0\\) \\(\\beta_1\\).MSE unbiased estimator \\(\\sigma^2\\), expected value true value.\\[ E(MSE) = \\sigma^2\\]estimates \\(\\beta\\)’s random variables. expect \\(b_1\\) change sampling. repeat sampling, expect MSE average \\(\\thicksim\\sigma^2\\).\\[\n\\sigma^2(b_1) = \\frac{\\sigma^2}{\\sum(x_i -\\bar x)^2}\n\\],Definition 2.9  (Estimation Variance) \\[\ns^2(b_1)=\\frac{MSE}{\\sum(x_i -\\bar x)^2}\n\\]’ll use p-value confidence interval calculations.","code":""},{"path":"modeling-and-errors.html","id":"examples-1","chapter":"2 Modeling and Errors","heading":"Examples","text":"Example 2.2  predicted model Example [] close, quite line true regression line. Determine errors:\\[\\begin{equation}\n\\begin{split}\n\nSSE &= \\sum_{= 1}^{n}e_i^2 \\approx 4457.83\\\\\nMSE &= \\frac{SSE}{n-2}\\approx 247\\\\\ns^2(b_1) &= \\frac{MSE}{\\sum(x-\\bar{ x})^2} \\approx 0.04067\\\\\ns(b_1) &= \\sqrt(0.04067) \\approx 0.202\n\\end{split}\n\\end{equation}\\]’ll use hypothesis testing next chapter.","code":""},{"path":"two-sided-t-testing.html","id":"two-sided-t-testing","chapter":"3 Two-Sided t-Testing","heading":"3 Two-Sided t-Testing","text":"SummaryTwo-sided t-testing good introduction hypothesis testing samples small distribution data known. Given simple example blood pressure study, section breaks can come conclusion model using three different approaches.concepts point revisited -depth.three approaches two-sided hypothesis testing:three render conclusion use significance level, \\(\\alpha\\).P-valuesCritical Values (t-Testing)Confidence IntervalsGiven null (\\(H_0\\)) alternative (\\(H_1\\)) hypotheses:\\[\\begin{align}\nH_0: \\beta_1 = 0\\\\\nH_1: \\beta_1 \\neq 0\n\\end{align}\\]\\(b_1\\sim N\\) \\(E(b_1) = \\beta_1\\), can build test statistic, \\(t^*\\):Definition 3.1  (t-statistic) \\[\\begin{equation}\n\\begin{split}\nt^* &= \\frac{b_1}{s(b_1)}\\\\\n&= \\sqrt{\\frac{MSE}{\\sum(x_1-\\bar{x})^2}}\n\\end{split}\n\\end{equation}\\]\\(H_0\\) true, \\(t^*\\) t-distribution \\(n-2\\) degrees freedom.derive deviation \\(b_1\\) variance, \\(s(b_1) = \\sqrt{s^2(b_1)}\\).","code":""},{"path":"two-sided-t-testing.html","id":"p-values","chapter":"3 Two-Sided t-Testing","heading":"3.1 P-values","text":"p-value \\(\\lt\\alpha\\), reject \\(H_0\\). Otherwise, reject \\(H_0\\).\\[ 2P(t \\leq |t^*|\\mid H_0 true)\\]Example 3.1  Continuing example [] estimate true regression line reasonable estimate? Let \\(\\alpha = 0.5\\).\\[\\begin{align}\nH_0: \\beta_1 = 0\\\\\nH_1: \\beta_1 \\neq 0\n\\end{align}\\]\\[\\begin{align}\nt^* = \\frac{b_1}{s(b_1)}\\\\\nt^* = \\frac{0.8}{0.202} \\approx 3.96\n\n\\end{align}\\]test statistic, \\(t^* = 3.96\\), returns p-value \\(0.0009\\). p-value smaller \\(\\alpha\\).p-val:\\[2P(t > 3.96) \\approx 0.0009\\]\\[0.0009 < 0.05 \\checkmark\\]\nReject null hypothesis. sufficient evidence conclude relationship predictor \\(X\\) outcome \\(Y\\).","code":""},{"path":"two-sided-t-testing.html","id":"critical-values","chapter":"3 Two-Sided t-Testing","heading":"3.2 Critical Values","text":"\\(|t^*| > t(1-\\frac{\\alpha}{2}; n-2)\\), reject \\(H_0\\). Otherwise, reject \\(H_0\\).\\[\nt(1-\\frac{\\alpha}{2}; n-2)\n\\]Example 3.2  Use critical values \\(t^*\\) determine reasonable model.\\[\\begin{equation}\n\\begin{split}\n|t^*| &\\stackrel{?}{>} t(1-\\frac{0.05}{2}; 20-2)\\\\\n|t^*| &\\stackrel{?}{>}t(0.975; 18)\\approx2.101\\\\\n3.96 &\\stackrel{?}{>} 2.101\n\n\\end{split}\n\\end{equation}\\]t-statistic \\(|t^*|\\) greater critical value \\(\\alpha =0.05\\). Reject null hypothesis.","code":""},{"path":"two-sided-t-testing.html","id":"confidence-intervals","chapter":"3 Two-Sided t-Testing","heading":"3.3 Confidence Intervals","text":"confidence interval contains set reasonable estimates parameter, given \\(\\alpha\\).Definition 3.2  (Confidence Interval) Upper lower bounds can found using following generic formula:estimate \\(\\pm\\) (critical value)*\\(s\\)(estimate)\\(b_1\\):\\[\nb_1 \\pm t(1-\\frac{\\alpha}{2}; n-2)s(b_1)\n\\]Expect different interval study repeated. slope variance vary study. \\(\\alpha = 0.05\\), expect \\(95\\%\\) confidence interval bands contain \\(\\beta_1\\).Example 3.3  Estimate 95% confidence interval favorite blood pressure study.Lower Bound:\\[\\begin{equation}\n\\begin{split}\nL &= b_1 - t(0.975; 18)s(b_1) \\\\\n   &= 0.8 - 2.101(0.202) \\approx 0.38\n\\end{split}\n\\end{equation}\\]Upper Bound:\\[\\begin{equation}\n\\begin{split}\nU &= b_1 + t(0.975; 18)s(b_1) \\\\\n   &= 0.8 + 2.101(0.202) \\approx 1.2\n\\end{split}\n\\end{equation}\\]95% confident \\(\\beta_1\\) confidence interval \\((0.38,1.2)\\).","code":""},{"path":"style-guide.html","id":"style-guide","chapter":"4 Style Guide","heading":"4 Style Guide","text":"help Bookdown, Rmarkdown Cookbook, little Office Ipsum. Markdown Extensions","code":""},{"path":"style-guide.html","id":"general-content","chapter":"4 Style Guide","heading":"4.0.1 General Content","text":"’s mixter general .SummaryThese summary notes thoughts start chapter. Use .recap tag optional .centered header.really like colour can change , make sexy, animation work, print page. best can can black darker jazz little, ideal world like , can snow look little warmer royalties company instead cash.test material. Use testmaterial flag. Latex boxes tend built-padding, expect big ol’ boxes like :\\[\\begin{equation}\ny = mx+b\n\\tag{4.1}\n\\end{equation}\\]Oh ’s figure (4.1). ’ll know see sandwich needs playful, yet think need start scratch sandwich needs playful. Can run inline? Remember , grade depends . Yeah works . Can black darker can retro, jazz little. red red according brief. work us “pro bono” really add portfolio promise ’ll know see actual logo instead font, don’t need backup, never goes !Office ipsum gives anxiety sometimes. Use [Remember ]{class=\"tm-inline\"} inline boxes.Can get .note standalone? Yes, heck yes can. Mixins!","code":""},{"path":"style-guide.html","id":"examples-2","chapter":"4 Style Guide","heading":"4.0.2 Examples","text":"color: Warning please, please help make sense monster practical applications.Example 4.1  sample problem. may mix plain text LaTex. Flexboxes multi-paragraph sections don’t play nice now. Use .example tags.\\[\ny-y_0 = m(x-x_0)\n\\]\nAnyway, designer, know can help ? get lot free exposure can remove double chin business card photo? don’t like way looks yet low resolution? looks ok screen. Can use high definition screenshot can handle million one go, agencies charge much lesser, lucky even us, actual logo instead font. Can please send design specs ?color: Success Hashtag winning? Two examples better one, guess. Though expect use color infrequently. ’s great color, though.Example 4.2  another sample problem. may mix plain text LaTex. Use .example .example2 tags.\\[\ny-x_0 \\neq m(x-y_0)\n\\]\nlove , can invert colors? just think. trust , ’ll know see . got invoice…seems really high.","code":""},{"path":"style-guide.html","id":"definitions","chapter":"4 Style Guide","heading":"4.0.3 Definitions","text":"color: Info Oh hey, look. Purple LaTex! inline badges! Pretty proud one.\\[\ny = x^2 + x - 1\n\\]chance can get color inline? Yeah, certainly. Use square-curly bracket combination, [definition]{class=\"text-info\"}.Definition 4.1  definition callout. numbering reliant Pandocs internal .definition class. Use .definition .defn build definition numbering, just .defn box without.","code":""},{"path":"style-guide.html","id":"dangers","chapter":"4 Style Guide","heading":"4.0.4 Dangers","text":"callout danger text. printed , animated gif moving. big name portfolio don’t need contract, can make pop. needs , totally different can handle million one go.","code":""}]
